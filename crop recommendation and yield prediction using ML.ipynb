{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Crop Recommendation"
      ],
      "metadata": {
        "id": "Qp_YLTP-Rj1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "1XpgqpZhJ-LW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsU_3pPiBOwj",
        "outputId": "f222893c-19af-4f1a-c354-023e294c2a32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    N   P   K  temperature   humidity        ph    rainfall label\n",
            "0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice\n",
            "1  85  58  41    21.770462  80.319644  7.038096  226.655537  rice\n",
            "2  60  55  44    23.004459  82.320763  7.840207  263.964248  rice\n",
            "3  74  35  40    26.491096  80.158363  6.980401  242.864034  rice\n",
            "4  78  42  42    20.130175  81.604873  7.628473  262.717340  rice\n",
            "Accuracy: 0.9954545454545455\n",
            "Enter temperature: 56\n",
            "Enter humidity: 34\n",
            "Enter rainfall: 879.90\n",
            "Enter nitrogen level: 34\n",
            "Enter phosphorous level: 56\n",
            "Enter potassium level: 67\n",
            "Enter pH value: 8.9\n",
            "Recommended crop: muskmelon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/Crop_recommendation.csv')\n",
        "\n",
        "# Display the first few rows of the dataset to understand its structure\n",
        "print(data.head())\n",
        "\n",
        "# Split dataset into features and target variable\n",
        "X = data.drop('label', axis=1)\n",
        "y = data['label']\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Function to recommend crop based on user inputs\n",
        "def recommend_crop(temperature, humidity, rainfall, nitrogen, phosphorous, potassium, ph):\n",
        "    user_input = [[temperature, humidity, rainfall, nitrogen, phosphorous, potassium, ph]]\n",
        "    predicted_crop = clf.predict(user_input)\n",
        "    return predicted_crop[0]\n",
        "\n",
        "# Example usage\n",
        "temperature = float(input(\"Enter temperature: \"))\n",
        "humidity = float(input(\"Enter humidity: \"))\n",
        "rainfall = float(input(\"Enter rainfall: \"))\n",
        "nitrogen = float(input(\"Enter nitrogen level: \"))\n",
        "phosphorous = float(input(\"Enter phosphorous level: \"))\n",
        "potassium = float(input(\"Enter potassium level: \"))\n",
        "ph = float(input(\"Enter pH value: \"))\n",
        "\n",
        "recommended_crop = recommend_crop(temperature, humidity, rainfall, nitrogen, phosphorous, potassium, ph)\n",
        "print(\"Recommended crop:\", recommended_crop)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/Crop_recommendation.csv')  # Make sure to change the filename to your dataset\n",
        "\n",
        "# Display the first few rows of the dataset to understand its structure\n",
        "print(data.head())\n",
        "\n",
        "# Split dataset into features and target variable\n",
        "X = data.drop('label', axis=1)  # Features\n",
        "y = data['label']                # Target variable\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Other classification evaluation metrics\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Function to recommend crop based on user inputs\n",
        "def recommend_crop(temperature, humidity, rainfall, nitrogen, phosphorous, potassium, ph):\n",
        "    user_input = [[temperature, humidity, rainfall, nitrogen, phosphorous, potassium, ph]]\n",
        "    predicted_crop = clf.predict(user_input)\n",
        "    return predicted_crop[0]\n",
        "\n",
        "# Example usage\n",
        "temperature = float(input(\"Enter temperature: \"))\n",
        "humidity = float(input(\"Enter humidity: \"))\n",
        "rainfall = float(input(\"Enter rainfall: \"))\n",
        "nitrogen = float(input(\"Enter nitrogen level: \"))\n",
        "phosphorous = float(input(\"Enter phosphorous level: \"))\n",
        "potassium = float(input(\"Enter potassium level: \"))\n",
        "ph = float(input(\"Enter pH value: \"))\n",
        "\n",
        "recommended_crop = recommend_crop(temperature, humidity, rainfall, nitrogen, phosphorous, potassium, ph)\n",
        "print(\"Recommended crop:\", recommended_crop)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEZkjg24luLr",
        "outputId": "6479ebeb-252f-4bdd-fce8-7aa19dc7cf9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    N   P   K  temperature   humidity        ph    rainfall label\n",
            "0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice\n",
            "1  85  58  41    21.770462  80.319644  7.038096  226.655537  rice\n",
            "2  60  55  44    23.004459  82.320763  7.840207  263.964248  rice\n",
            "3  74  35  40    26.491096  80.158363  6.980401  242.864034  rice\n",
            "4  78  42  42    20.130175  81.604873  7.628473  262.717340  rice\n",
            "Accuracy: 0.9931818181818182\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       apple       1.00      1.00      1.00        23\n",
            "      banana       1.00      1.00      1.00        21\n",
            "   blackgram       1.00      1.00      1.00        20\n",
            "    chickpea       1.00      1.00      1.00        26\n",
            "     coconut       1.00      1.00      1.00        27\n",
            "      coffee       1.00      1.00      1.00        17\n",
            "      cotton       1.00      1.00      1.00        17\n",
            "      grapes       1.00      1.00      1.00        14\n",
            "        jute       0.92      1.00      0.96        23\n",
            " kidneybeans       1.00      1.00      1.00        20\n",
            "      lentil       0.92      1.00      0.96        11\n",
            "       maize       1.00      1.00      1.00        21\n",
            "       mango       1.00      1.00      1.00        19\n",
            "   mothbeans       1.00      0.96      0.98        24\n",
            "    mungbean       1.00      1.00      1.00        19\n",
            "   muskmelon       1.00      1.00      1.00        17\n",
            "      orange       1.00      1.00      1.00        14\n",
            "      papaya       1.00      1.00      1.00        23\n",
            "  pigeonpeas       1.00      1.00      1.00        23\n",
            " pomegranate       1.00      1.00      1.00        23\n",
            "        rice       1.00      0.89      0.94        19\n",
            "  watermelon       1.00      1.00      1.00        19\n",
            "\n",
            "    accuracy                           0.99       440\n",
            "   macro avg       0.99      0.99      0.99       440\n",
            "weighted avg       0.99      0.99      0.99       440\n",
            "\n",
            "Confusion Matrix:\n",
            "[[23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 21  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 27  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 23  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 21  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  1  0  0 23  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0 17  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19]]\n",
            "Enter temperature: 9\n",
            "Enter humidity: 80\n",
            "Enter rainfall: 76.98\n",
            "Enter nitrogen level: 23\n",
            "Enter phosphorous level: 12\n",
            "Enter potassium level: 34\n",
            "Enter pH value: 7.8\n",
            "Recommended crop: chickpea\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machine"
      ],
      "metadata": {
        "id": "8HQ_aB_KKHmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/Crop_recommendation.csv')  # Make sure to change the filename to your dataset\n",
        "\n",
        "# Display the first few rows of the dataset to understand its structure\n",
        "print(data.head())\n",
        "\n",
        "# Split dataset into features and target variable\n",
        "X = data.drop('label', axis=1)  # Features\n",
        "y = data['label']                # Target variable\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an SVM classifier\n",
        "clf = SVC(kernel='linear')\n",
        "\n",
        "# Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Function to recommend crop based on user inputs\n",
        "def recommend_crop(temperature, humidity, rainfall, nitrogen, phosphorous, potassium, ph):\n",
        "    user_input = [[temperature, humidity, rainfall, nitrogen, phosphorous, potassium, ph]]\n",
        "    predicted_crop = clf.predict(user_input)\n",
        "    return predicted_crop[0]\n",
        "\n",
        "# Example usage\n",
        "temperature = float(input(\"Enter temperature: \"))\n",
        "humidity = float(input(\"Enter humidity: \"))\n",
        "rainfall = float(input(\"Enter rainfall: \"))\n",
        "nitrogen = float(input(\"Enter nitrogen level: \"))\n",
        "phosphorous = float(input(\"Enter phosphorous level: \"))\n",
        "potassium = float(input(\"Enter potassium level: \"))\n",
        "ph = float(input(\"Enter pH value: \"))\n",
        "\n",
        "recommended_crop = recommend_crop(temperature, humidity, rainfall, nitrogen, phosphorous, potassium, ph)\n",
        "print(\"Recommended crop:\", recommended_crop)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P3yP9GHJgjJ",
        "outputId": "4fece6be-5c94-4d48-819a-496153b6b15a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    N   P   K  temperature   humidity        ph    rainfall label\n",
            "0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice\n",
            "1  85  58  41    21.770462  80.319644  7.038096  226.655537  rice\n",
            "2  60  55  44    23.004459  82.320763  7.840207  263.964248  rice\n",
            "3  74  35  40    26.491096  80.158363  6.980401  242.864034  rice\n",
            "4  78  42  42    20.130175  81.604873  7.628473  262.717340  rice\n",
            "Accuracy: 0.9795454545454545\n",
            "Enter temperature: 90\n",
            "Enter humidity: 34\n",
            "Enter rainfall: 234.67\n",
            "Enter nitrogen level: 45\n",
            "Enter phosphorous level: 76\n",
            "Enter potassium level: 12\n",
            "Enter pH value: 6.8\n",
            "Recommended crop: grapes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/Crop_recommendation.csv')  # Make sure to change the filename to your dataset\n",
        "\n",
        "# Display the first few rows of the dataset to understand its structure\n",
        "print(data.head())\n",
        "\n",
        "# Split dataset into features and target variable\n",
        "X = data.drop('label', axis=1)  # Features\n",
        "y = data['label']                # Target variable\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an SVM classifier\n",
        "clf = SVC(kernel='linear')\n",
        "\n",
        "# Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Other classification evaluation metrics\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Function to recommend crop based on user inputs\n",
        "def recommend_crop(temperature, humidity, rainfall, nitrogen, phosphorous, potassium, ph):\n",
        "    user_input = [[temperature, humidity, rainfall, nitrogen, phosphorous, potassium, ph]]\n",
        "    predicted_crop = clf.predict(user_input)\n",
        "    return predicted_crop[0]\n",
        "\n",
        "# Example usage\n",
        "temperature = float(input(\"Enter temperature: \"))\n",
        "humidity = float(input(\"Enter humidity: \"))\n",
        "rainfall = float(input(\"Enter rainfall: \"))\n",
        "nitrogen = float(input(\"Enter nitrogen level: \"))\n",
        "phosphorous = float(input(\"Enter phosphorous level: \"))\n",
        "potassium = float(input(\"Enter potassium level: \"))\n",
        "ph = float(input(\"Enter pH value: \"))\n",
        "\n",
        "recommended_crop = recommend_crop(temperature, humidity, rainfall, nitrogen, phosphorous, potassium, ph)\n",
        "print(\"Recommended crop:\", recommended_crop)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPx5KwwKmfWw",
        "outputId": "86a631b9-514a-41f1-e564-ed10d4f39c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    N   P   K  temperature   humidity        ph    rainfall label\n",
            "0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice\n",
            "1  85  58  41    21.770462  80.319644  7.038096  226.655537  rice\n",
            "2  60  55  44    23.004459  82.320763  7.840207  263.964248  rice\n",
            "3  74  35  40    26.491096  80.158363  6.980401  242.864034  rice\n",
            "4  78  42  42    20.130175  81.604873  7.628473  262.717340  rice\n",
            "Accuracy: 0.9795454545454545\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       apple       1.00      1.00      1.00        23\n",
            "      banana       1.00      1.00      1.00        21\n",
            "   blackgram       0.95      1.00      0.98        20\n",
            "    chickpea       1.00      1.00      1.00        26\n",
            "     coconut       1.00      1.00      1.00        27\n",
            "      coffee       0.94      1.00      0.97        17\n",
            "      cotton       0.94      1.00      0.97        17\n",
            "      grapes       1.00      1.00      1.00        14\n",
            "        jute       0.87      0.87      0.87        23\n",
            " kidneybeans       1.00      1.00      1.00        20\n",
            "      lentil       1.00      1.00      1.00        11\n",
            "       maize       1.00      0.95      0.98        21\n",
            "       mango       0.95      1.00      0.97        19\n",
            "   mothbeans       1.00      1.00      1.00        24\n",
            "    mungbean       1.00      1.00      1.00        19\n",
            "   muskmelon       1.00      1.00      1.00        17\n",
            "      orange       1.00      1.00      1.00        14\n",
            "      papaya       0.96      1.00      0.98        23\n",
            "  pigeonpeas       1.00      0.91      0.95        23\n",
            " pomegranate       1.00      1.00      1.00        23\n",
            "        rice       0.94      0.84      0.89        19\n",
            "  watermelon       1.00      1.00      1.00        19\n",
            "\n",
            "    accuracy                           0.98       440\n",
            "   macro avg       0.98      0.98      0.98       440\n",
            "weighted avg       0.98      0.98      0.98       440\n",
            "\n",
            "Confusion Matrix:\n",
            "[[23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 21  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 27  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  0  0 20  0  0  0  0  0  0  0  0  1  0  0  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 24  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0 21  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0 16  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19]]\n",
            "Enter temperature: 120\n",
            "Enter humidity: 12\n",
            "Enter rainfall: 12.89\n",
            "Enter nitrogen level: 78\n",
            "Enter phosphorous level: 90\n",
            "Enter potassium level: 67\n",
            "Enter pH value: 3.4\n",
            "Recommended crop: muskmelon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yield Prediction"
      ],
      "metadata": {
        "id": "G4VXskdU2O4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "KagZjizEc5Wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/crop_yield.csv')\n",
        "\n",
        "# Drop 'Production' column\n",
        "df = df.drop('Production', axis=1)\n",
        "\n",
        "# Scale numerical features\n",
        "numerical_features = ['Crop_Year', 'Area', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
        "scaler = StandardScaler()\n",
        "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "category_columns = df.select_dtypes(include=['object']).columns\n",
        "df = pd.get_dummies(df, columns=category_columns, drop_first=True)\n",
        "\n",
        "# Split features and target variable\n",
        "X = df.drop('Yield', axis=1)\n",
        "y = df['Yield']\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define RandomForestRegressor\n",
        "rfr = RandomForestRegressor()\n",
        "\n",
        "# Define hyperparameters for tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_features': ['auto', 'sqrt']\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV for hyperparameter tuning\n",
        "grid_cv = GridSearchCV(estimator=rfr, param_grid=param_grid, scoring='r2', cv=5)\n",
        "grid_cv.fit(X_train, y_train)\n",
        "\n",
        "# Get best parameters\n",
        "best_params = grid_cv.best_params_\n",
        "# Train Random Forest Regressor with best parameters\n",
        "rf_regressor = RandomForestRegressor(n_estimators=best_params['n_estimators'], max_features=best_params['max_features'])\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict the response for test dataset\n",
        "y_pred = rf_regressor.predict(X_test)\n",
        "\n",
        "# Model Evaluation\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R-squared:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKLeUL9gPSDd",
        "outputId": "9d8bbcde-ed0f-4027-c4d4-c53ecbd1ad62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 105778.8649975079\n",
            "R-squared: 0.8638715785986633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/crop_yield.csv')\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['Crop', 'Crop_Year', 'Season', 'State', 'Area', 'Annual_Rainfall', 'Fertilizer', 'Pesticide', 'Yield']\n",
        "data = data[features]  # Include 'Yield' in features list\n",
        "X = data.drop(columns=['Yield'])  # Exclude 'Yield' as a feature\n",
        "y = data['Yield']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define preprocessing steps for numerical and categorical features\n",
        "numeric_features = ['Crop_Year', 'Area', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_features = ['Crop', 'Season', 'State']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Append the regression model to the preprocessing steps\n",
        "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('regressor', RandomForestRegressor())])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get input from the user\n",
        "user_input = {}\n",
        "for feature in features[:-1]:  # Exclude 'Yield' from user input\n",
        "    user_input[feature] = input(f\"Enter {feature.replace('_', ' ')}: \")\n",
        "\n",
        "# Make predictions on the new data point\n",
        "new_data = pd.DataFrame([user_input])\n",
        "predicted_yield = model.predict(new_data)\n",
        "\n",
        "print(f'Predicted Yield: {predicted_yield[0]}')\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate R2 score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'R2 Score: {r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH5PotAEQVke",
        "outputId": "97c14b4a-c6dc-48e6-d0d5-f35b4bb07e78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Crop: rice\n",
            "Enter Crop Year: 2019\n",
            "Enter Season: summer\n",
            "Enter State: tamil nadu\n",
            "Enter Area: 34567\n",
            "Enter Annual Rainfall: 890\n",
            "Enter Fertilizer: 780\n",
            "Enter Pesticide: 66789\n",
            "Predicted Yield: 0.8925659025\n",
            "R2 Score: 0.9786055877403097\n"
          ]
        }
      ]
    }
  ]
}